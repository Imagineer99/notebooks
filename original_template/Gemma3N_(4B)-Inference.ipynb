{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Placeholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --no-deps \"transformers>=4.53.0\" # For Gemma 3N\n",
        "!pip install --no-deps --upgrade timm # For Gemma 3N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGMWlrRdzwgf"
      },
      "source": [
        "### Unsloth\n",
        "\n",
        "`FastModel` supports loading nearly any model now! This includes Vision and Text models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Xbb0cuLzwgf"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastModel\n",
        "import torch\n",
        "\n",
        "fourbit_models = [\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3n-E4B-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-it-unsloth-bnb-4bit\",\n",
        "    # Pretrained models\n",
        "    \"unsloth/gemma-3n-E4B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3n-E2B-unsloth-bnb-4bit\",\n",
        "\n",
        "    # Other Gemma 3 quants\n",
        "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name = \"unsloth/gemma-3n-E2B-it\",\n",
        "    dtype = None, # None for auto detection\n",
        "    max_seq_length = 1024, # Choose any for long context!\n",
        "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        "    # token = \"hf_...\", # use one if using gated models\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nSv73tRgyzp"
      },
      "source": [
        "## Let's make some utilities so Gemma 3N can process any medium!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8KQHLiOX5YU"
      },
      "outputs": [],
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "def gemma_3n_inference(messages, max_new_tokens = 128):\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt = True, # Must add for generation\n",
        "        tokenize = True,\n",
        "        return_dict = True,\n",
        "        return_tensors = \"pt\",\n",
        "    ).to(\"cuda\")\n",
        "    _ = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens = max_new_tokens, # Increase for longer outputs!\n",
        "        # Recommended Gemma-3N settings!\n",
        "        temperature = 1.0, top_p = 0.95, top_k = 64,\n",
        "        streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UascJ0JcZCu"
      },
      "source": [
        "# Gemma 3N can process Text, Vision and Audio!\n",
        "\n",
        "Wait a minute or so for Unsloth to auto compile Gemma 3N!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR3gIAX-SM2q"
      },
      "outputs": [],
      "source": [
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{ \"type\" : \"text\",\n",
        "                  \"text\" : \"Continue the sequence: 1, 1, 2, 3, 5, 8,\" }]\n",
        "}]\n",
        "gemma_3n_inference(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWXEtrssOlFS"
      },
      "source": [
        "Let's make a poem about sloths!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp8BlhUKrbBL"
      },
      "outputs": [],
      "source": [
        "messages = [{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": [{ \"type\" : \"text\",\n",
        "                  \"text\" : \"Write a poem about sloths.\" }]\n",
        "}]\n",
        "gemma_3n_inference(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX8_HvzUNdGP"
      },
      "source": [
        "# Gemma 3N can see images!\n",
        "\n",
        "<img src=\"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\" alt=\"Alt text\" height=\"256\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oBuWJISburR"
      },
      "outputs": [],
      "source": [
        "sloth_link = \"https://files.worldwildlife.org/wwfcmsprod/images/Sloth_Sitting_iStock_3_12_2014/story_full_width/8l7pbjmj29_iStock_000011145477Large_mini__1_.jpg\"\n",
        "\n",
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"image\", \"image\" : sloth_link },\n",
        "        { \"type\": \"text\",  \"text\" : \"Which films does this animal feature in?\" }\n",
        "    ]\n",
        "}]\n",
        "gemma_3n_inference(messages, max_new_tokens = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YkxKEqcPNrF"
      },
      "source": [
        "# Let's let Gemma 3N understand itself!\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_5lfhlBO.original.png\" alt=\"Alt text\" height=\"256\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPelmxE_P4qE"
      },
      "outputs": [],
      "source": [
        "picture_link = \"https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_5lfhlBO.original.png\"\n",
        "\n",
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"image\", \"image\" : picture_link },\n",
        "        { \"type\": \"text\",  \"text\" : \"What is this image about?\" }\n",
        "    ]\n",
        "}]\n",
        "gemma_3n_inference(messages, max_new_tokens = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rypu2ACfaSu"
      },
      "source": [
        "# Gemma 3N can also hear!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvmNylD0fjtG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display\n",
        "Audio(\"https://upload.wikimedia.org/wikipedia/en/6/61/I_Have_A_Dream_sample.ogg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au4x9K94Rx0_"
      },
      "outputs": [],
      "source": [
        "!wget -qqq https://upload.wikimedia.org/wikipedia/en/6/61/I_Have_A_Dream_sample.ogg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFOhzC57fagL"
      },
      "outputs": [],
      "source": [
        "audio_file = \"I_Have_A_Dream_sample.ogg\"\n",
        "\n",
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"audio\", \"audio\" : audio_file },\n",
        "        { \"type\": \"text\",  \"text\" : \"What is this audio about?\" }\n",
        "    ]\n",
        "}]\n",
        "gemma_3n_inference(messages, max_new_tokens = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04MmoMSWR-Hr"
      },
      "source": [
        "# Let's combine all 3 together!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJrmoyN0SDOV"
      },
      "outputs": [],
      "source": [
        "messages = [{\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": [\n",
        "        { \"type\": \"audio\", \"audio\" : audio_file },\n",
        "        { \"type\": \"image\", \"image\" : sloth_link },\n",
        "        { \"type\": \"text\",  \"text\" : \"What is the image and audio about?\\n\"\\\n",
        "                                    \"How are they related?\" }\n",
        "    ]\n",
        "}]\n",
        "gemma_3n_inference(messages, max_new_tokens = 256)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
